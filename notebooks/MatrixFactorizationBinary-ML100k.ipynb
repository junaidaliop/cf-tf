{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_data(base_path='./', delimiter='\\t', threshold=3):\n",
    "    \"\"\"\n",
    "    Load MovieLens data and preprocess it by binarizing the ratings.\n",
    "\n",
    "    Args:\n",
    "    base_path (str): Base path to the dataset files.\n",
    "    delimiter (str): Delimiter used in the dataset files.\n",
    "    threshold (int): Threshold rating to decide likes and dislikes.\n",
    "\n",
    "    Returns:\n",
    "    Tuple: Number of users, number of movies, binarized training and testing rating matrices.\n",
    "    \"\"\"\n",
    "    # Load training and testing data\n",
    "    train_data = pd.read_csv(base_path + 'movielens_100k_u1.base', sep=delimiter, header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "    test_data = pd.read_csv(base_path + 'movielens_100k_u1.test', sep=delimiter, header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "    # Determine the number of users and movies\n",
    "    num_users = max(train_data['user_id'].max(), test_data['user_id'].max())\n",
    "    num_movies = max(train_data['movie_id'].max(), test_data['movie_id'].max())\n",
    "\n",
    "    # Initialize matrices to store binarized ratings\n",
    "    train_ratings = np.zeros((num_users, num_movies))\n",
    "    test_ratings = np.zeros((num_users, num_movies))\n",
    "\n",
    "    # Fill the matrices with binarized ratings\n",
    "    for row in train_data.itertuples():\n",
    "        train_ratings[row.user_id - 1, row.movie_id - 1] = 1 if row.rating >= threshold else 0\n",
    "    for row in test_data.itertuples():\n",
    "        test_ratings[row.user_id - 1, row.movie_id - 1] = 1 if row.rating >= threshold else 0\n",
    "\n",
    "    return num_users, num_movies, train_ratings, test_ratings\n",
    "\n",
    "# Load and preprocess data\n",
    "num_users, num_movies, train_ratings_binarized, test_ratings_binarized = load_and_preprocess_data('./data/MovieLens_100K/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_ratings: (943, 1682)\n",
      "Shape of test_ratings: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_ratings:\", train_ratings_binarized.shape)\n",
    "print(\"Shape of test_ratings:\", test_ratings_binarized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "Positive samples: 66103 (4.17%)\n",
      "Negative samples: 1520023 (95.83%)\n",
      "\n",
      "Testing set distribution:\n",
      "Positive samples: 16417 (1.04%)\n",
      "Negative samples: 1569709 (98.96%)\n"
     ]
    }
   ],
   "source": [
    "def check_distribution(ratings_matrix):\n",
    "    positive_count = np.sum(ratings_matrix >= 1)\n",
    "    negative_count = np.sum(ratings_matrix == 0)\n",
    "    total_count = positive_count + negative_count\n",
    "    print(f\"Positive samples: {positive_count} ({positive_count / total_count * 100:.2f}%)\")\n",
    "    print(f\"Negative samples: {negative_count} ({negative_count / total_count * 100:.2f}%)\")\n",
    "\n",
    "print(\"Training set distribution:\")\n",
    "check_distribution(train_ratings_binarized)\n",
    "\n",
    "print(\"\\nTesting set distribution:\")\n",
    "check_distribution(test_ratings_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " movie_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 32)                30176     ['user_input[0][0]']          \n",
      "                                                                                                  \n",
      " movie_embedding (Embedding  (None, 1, 32)                53824     ['movie_input[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flattened_user_embedding (  (None, 32)                   0         ['user_embedding[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Flatten)                                                                                         \n",
      "                                                                                                  \n",
      " flattened_movie_embedding   (None, 32)                   0         ['movie_embedding[0][0]']     \n",
      " (Flatten)                                                                                        \n",
      "                                                                                                  \n",
      " interaction_layer (Dot)     (None, 1)                    0         ['flattened_user_embedding[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'flattened_movie_embedding[0]\n",
      "                                                                    [0]']                         \n",
      "                                                                                                  \n",
      " output_layer (Dense)        (None, 1)                    2         ['interaction_layer[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 84002 (328.13 KB)\n",
      "Trainable params: 84002 (328.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, F1Score\n",
    "\n",
    "def build_binary_recommendation_model(num_users, num_movies, latent_dim=32):\n",
    "    \"\"\"\n",
    "    Build a binary classification recommendation model.\n",
    "\n",
    "    Args:\n",
    "    - num_users (int): The total number of users in the dataset.\n",
    "    - num_movies (int): The total number of movies in the dataset.\n",
    "    - latent_dim (int): The number of dimensions in the embedding space.\n",
    "\n",
    "    Returns:\n",
    "    - Model: A Keras model instance.\n",
    "    \"\"\"\n",
    "    # User and movie input layers\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    movie_input = Input(shape=(1,), name='movie_input')\n",
    "\n",
    "    # Embedding layers for users and movies\n",
    "    user_embedding = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding')(user_input)\n",
    "    movie_embedding = Embedding(input_dim=num_movies, output_dim=latent_dim, name='movie_embedding')(movie_input)\n",
    "\n",
    "    # Flatten the embeddings and compute the dot product\n",
    "    user_vector = Flatten(name='flattened_user_embedding')(user_embedding)\n",
    "    movie_vector = Flatten(name='flattened_movie_embedding')(movie_embedding)\n",
    "    interaction = Dot(axes=1, name='interaction_layer')([user_vector, movie_vector])\n",
    "\n",
    "    # Output layer with a sigmoid activation function for binary classification\n",
    "    output = Dense(1, activation='sigmoid', name='output_layer')(interaction)\n",
    "\n",
    "    # Compile the model with additional metrics\n",
    "    model = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Nadam(learning_rate=0.001),\n",
    "        metrics=['accuracy', Precision(), Recall(), F1Score()]  \n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the model with additional metrics\n",
    "binary_model = build_binary_recommendation_model(num_users, num_movies)\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1033/1033 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.9960 - precision_1: 1.0000 - recall_1: 0.9960 - f1_score: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 2/50\n",
      "1033/1033 [==============================] - 2s 2ms/step - loss: 0.0132 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - f1_score: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 3/50\n",
      "1033/1033 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - f1_score: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 4/50\n",
      "1033/1033 [==============================] - 2s 2ms/step - loss: 8.8194e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - f1_score: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 5/50\n",
      "1033/1033 [==============================] - 2s 1ms/step - loss: 3.7597e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - f1_score: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Epoch 6/50\n",
      "1033/1033 [==============================] - 2s 1ms/step - loss: 1.7723e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - f1_score: 1.0000 - val_loss: 8.9021e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - val_f1_score: 1.0000\n",
      "Number of positive samples in the test set: 16417\n",
      "Number of negative samples in the test set: 1569709\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Extracting the indices of non-zero ratings for training and validation\n",
    "train_user_ids, train_item_ids = train_ratings_binarized.nonzero()\n",
    "train_ratings = train_ratings_binarized[train_user_ids, train_item_ids]\n",
    "\n",
    "test_user_ids, test_item_ids = test_ratings_binarized.nonzero()\n",
    "test_ratings = test_ratings_binarized[test_user_ids, test_item_ids]\n",
    "\n",
    "\n",
    "# Training the model\n",
    "binary_model.fit(\n",
    "    [train_user_ids, train_item_ids],\n",
    "    train_ratings,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_data=([test_user_ids, test_item_ids], test_ratings),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# Check the number of positive and negative samples in the test set\n",
    "positive_samples = np.sum(test_ratings_binarized == 1)\n",
    "negative_samples = np.sum(test_ratings_binarized == 0)\n",
    "\n",
    "print(\"Number of positive samples in the test set:\", positive_samples)\n",
    "print(\"Number of negative samples in the test set:\", negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 661us/step\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions_probs = binary_model.predict([test_user_ids, test_item_ids]).flatten()\n",
    "test_predictions = (test_predictions_probs > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test_ratings, test_predictions)\n",
    "precision = precision_score(test_ratings, test_predictions)\n",
    "recall = recall_score(test_ratings, test_predictions)\n",
    "f1 = f1_score(test_ratings, test_predictions)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Parkinsons-TF",
   "language": "python",
   "name": "parkinsons-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
